{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "randomforest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKXahhqq9y-F"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('./heart_failure_clinical_records_dataset.csv') #importing dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycoheJcg94IR"
      },
      "source": [
        "x = df.drop(\"DEATH_EVENT\",axis=1) #axis needed #df.drop death event is the variable we are predicting, it is not a dependent variable it is a independent variable\n",
        "y = df[\"DEATH_EVENT\"] #what we are trying to predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILQF1zuY-DPj"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpJiAxGp95yZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn5n0qh8-KJQ"
      },
      "source": [
        "#randomforest = RandomForestClassifier(random_state=1,n_estimators=800,max_depth=20,min_samples_split=5,min_samples_leaf=1) #ideal parameters\n",
        "randomforest = RandomForestClassifier()\n",
        "randomforest.fit(x_train,y_train)\n",
        "y_prediction = randomforest.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enIf_8D-99om"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "H4eiBun49-Ij",
        "outputId": "8fd0dbad-627b-4eb9-bd22-5e2f1cc0a2b1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "classification_report(y_test,y_prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.93      1.00      0.97        43\\n           1       1.00      0.82      0.90        17\\n\\n    accuracy                           0.95        60\\n   macro avg       0.97      0.91      0.93        60\\nweighted avg       0.95      0.95      0.95        60\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03gqHPOxBq07"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owfPdF8eAGVc",
        "outputId": "bd1c6890-6491-445b-b222-917f9ce7eb18"
      },
      "source": [
        "n_estimators = [100,300,500,800,1200] #returns the result of hyperparamter tuning\n",
        "max_depth = [5,8,15,25,30]\n",
        "min_samples_split = [2,5,10,15,100]\n",
        "min_samples_leaf = [1,2,5,10]\n",
        "HyperP = dict(n_estimators = n_estimators, max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\n",
        "gridf = GridSearchCV(randomforest,HyperP,cv=3,verbose=1,n_jobs=-1)\n",
        "bestf = gridf.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   34.0s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed: 14.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 18.0min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ppOlHcugp2"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0bHd1_EsfuT",
        "outputId": "e394bfe1-bcdd-49a1-85ef-d6b46d90e107"
      },
      "source": [
        "%timeit randomforest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 40.67 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000000 loops, best of 5: 34.2 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72mq20Sdsgxl",
        "outputId": "a68007cc-1eb2-49e0-a546-110818930c6c"
      },
      "source": [
        "%timeit randomforest.fit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 58.27 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000000 loops, best of 5: 124 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN1kE7NpsiNr",
        "outputId": "53d343e8-3a8b-4006-a4cd-9d3dcd0a5b5c"
      },
      "source": [
        "%timeit y_prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000000 loops, best of 5: 29.8 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jH_Gz9UuHvN",
        "outputId": "3e68ce63-73aa-42a6-9545-6c3a9b343f91"
      },
      "source": [
        " %timeit gridf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 31.88 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000000 loops, best of 5: 32.4 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTubPR5zuRYL",
        "outputId": "2156ef41-4ed3-4938-c838-3845bda3f4f4"
      },
      "source": [
        "%timeit bestf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 42.95 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000000 loops, best of 5: 32.2 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAAPi2B8Z0ey",
        "outputId": "a1cddb35-1b7a-493d-b2d8-7a9a88f01ee1"
      },
      "source": [
        "pip install memory_profiler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting memory_profiler\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/fd/d92b3295657f8837e0177e7b48b32d6651436f0293af42b76d134c3bb489/memory_profiler-0.58.0.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-cp37-none-any.whl size=30180 sha256=729545de6447ad28e744c0fbf67b3af6d08a11ea9ff0c5b85cad550a799925d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/e4/0b/aaab481fc5dd2a4ea59e78bc7231bb6aae7635ca7ee79f8ae5\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.58.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqNN1HfdZ2-g"
      },
      "source": [
        "%load_ext memory_profiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_e9JkrDZ5gg",
        "outputId": "49447d6c-0950-487f-92ff-4fe2ef5316cd"
      },
      "source": [
        "%memit randomforest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 158.47 MiB, increment: 0.00 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HenVaS-PaKAp",
        "outputId": "39e8c8ed-e9d8-4a2e-bf46-c6df073078b2"
      },
      "source": [
        "%memit randomforest.fit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 158.47 MiB, increment: 0.00 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PWbEICoaLZZ",
        "outputId": "1ba2d6af-1a1c-40c1-8093-a7d740cc39f2"
      },
      "source": [
        "%memit y_prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 158.47 MiB, increment: 0.00 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmKQG79VaRdm",
        "outputId": "e3ab5def-3ad6-4587-f45e-26a57aecc691"
      },
      "source": [
        "%memit gridf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 158.47 MiB, increment: 0.00 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W83kbgPaU4W",
        "outputId": "b1e48a86-5538-4ccf-8a45-dcd42d4ceebd"
      },
      "source": [
        "%memit bestf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peak memory: 158.47 MiB, increment: 0.00 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3-0MALjzUYf"
      },
      "source": [
        "report = classification_report(y_test,y_prediction,output_dict = True)\n",
        "import seaborn as sns\n",
        "sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW_dFvTNzWt-"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "auc_score1 = roc_auc_score(y_test, y_prediction)\n",
        "print(auc_score1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg4v8xzNzd-i"
      },
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "metrics.plot_roc_curve(randomforest, x_test, y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IN0L5AgzgH0"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLNTPVvNziTJ"
      },
      "source": [
        "#Cost assumptions\n",
        "'''Cost of FP: 1, cost of FN: 2, cost of TN: 0, cost of TP: -1'''\n",
        "cost_TP = -1; cost_FP = 1; cost_FN = 2; cost_TN = 0;\n",
        "cb_matrix = -1*np.array([[cost_TP, cost_FP],[cost_FN, cost_TN]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i1h3awrzjt1"
      },
      "source": [
        "def standard_confusion_matrix(y_true, y_predict):\n",
        "    TP = sum((y_true == 1) & (y_predict == 1))\n",
        "    TN = sum((y_true == 0) & (y_predict == 0))\n",
        "    FP = sum((y_true == 0) & (y_predict == 1))\n",
        "    FN = sum((y_true == 1) & (y_predict == 0))\n",
        "    \n",
        "    return np.array([[TP,FP],[FN,TN]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu5yNAMPzlpv"
      },
      "source": [
        "def profit_curve(cb, predict_probas, labels):\n",
        "    indices = np.argsort(predict_probas)\n",
        "    sorted_probs = predict_probas[indices]\n",
        "    sorted_labels = labels[indices]\n",
        "    \n",
        "    profit_list = []\n",
        "    \n",
        "    for sp, sl in zip(sorted_probs, sorted_labels):\n",
        "        predict_labels = sorted_probs > sp + .0001\n",
        "        conf_mat = standard_confusion_matrix(sorted_labels, predict_labels)\n",
        "        profit_list.append((cb * conf_mat).sum() / float(len(labels)))\n",
        "    return profit_list, sorted_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCeNYR17zn8c"
      },
      "source": [
        "def plot_profit_curve(model, label, costbenefit, X_train, X_test, y_train, y_test, col):\n",
        "    model.fit(X_train, y_train)\n",
        "    predict_probas = model.predict_proba(X_test)[:,1]\n",
        "    profit_list, sorted_probs = profit_curve(costbenefit, predict_probas, y_test)\n",
        "    max_index = np.argmax(profit_list)\n",
        "    max_threshold = sorted_probs[max_index]\n",
        "    max_profit = profit_list[max_index]\n",
        "    \n",
        "    plt.plot(sorted_probs, profit_list, label=label, color=col, linewidth=3)\n",
        "    plt.plot(max_threshold, max_profit, '.', color=col, markersize=18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M7o2MH5zqU-"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1R41jg5zshY"
      },
      "source": [
        "models = [randomforest]\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "# fig.set_facecolor('#F2F2F2')\n",
        "colors = ['r', 'g', 'b', 'm']\n",
        "for i, model in enumerate(models):\n",
        "    plot_profit_curve(model, model.__class__.__name__, cb_matrix,\n",
        "                      x_train, x_test, y_train, y_test, colors[i])\n",
        "plt.title(\"Profit Curves\")\n",
        "plt.xlabel(\"Percentage of test instances (decreasing by score)\")\n",
        "plt.ylabel(\"Profit\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig('Profit_curve.png', facecolor=fig.get_facecolor())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSR9vSbuzyNG"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cf_matrix = confusion_matrix(y_test,y_prediction)\n",
        "print(cf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E7kU1Npz4Wt"
      },
      "source": [
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klT0vRnXz4pL"
      },
      "source": [
        "group_names = ['True Neg','false Pos','False Neg','True Pos']\n",
        "group_counts = ['{0:0.0f}'.format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "group_percentages = ['{0:.2%}'.format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCVV8kZW0ArW"
      },
      "source": [
        "https://stackoverflow.com/questions/28200786/how-to-plot-scikit-learn-classification-report\n",
        "https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea\n",
        "https://github.com/SydneyLauren/Profit-curves-and-xkcd-plotting\n",
        "https://community.datarobot.com/t5/resources/profit-curve/ta-p/7389\n",
        "https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n",
        "https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
        "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n",
        "https://gist.github.com/fclesio/bb5871281debc07d75127552c56b08b5\n",
        "https://stackoverflow.com/questions/61705257/sklearn-plotting-classification-report-gives-a-different-output-than-basic-avg\n",
        "https://www.pyimagesearch.com/2016/08/15/how-to-tune-hyperparameters-with-python-and-scikit-learn/\n",
        "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
        "https://towardsdatascience.com/optimizing-hyperparameters-in-random-forest-classification-ec7741f9d3f6\n",
        "\n"
      ]
    }
  ]
}